{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368acb6c-3cf8-4fc1-8f1d-140236f7e20a",
   "metadata": {},
   "source": [
    "# Tutorial 3 - Fitting a MLFF \n",
    "\n",
    "For this tutorial we also need to install PyTorch and PyTorch Geometric. We will build a pipeline to test an algorithm that you can define by yourself. \n",
    "\n",
    "## Environment setup \n",
    "\n",
    "We setup and PyTorch and PyTorch geometric using the `CPU` as most consumer hardware does not offer 64bit GPUs. For simulations we need as good of an accuracy we can get \n",
    "\n",
    "```bash \n",
    "conda create -n mlfftutorial3 python=3.11\n",
    "conda activate mlfftutorial3\n",
    "pip install torch_geometric\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "pip install mond\n",
    "```\n",
    "\n",
    "## Dataset \n",
    "\n",
    "We use the dataset generated in the previous tutorial. If you just want to test the algorithm fast without generating a dataset for a couple of hours, that's fine. The repo provides a test dataset. If you want to use the provided dataset, make sure to change the dataset path to `methanol_aimd_data_prerun`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b70595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from pathlib import Path\n",
    "\n",
    "class NPZTrajectoryDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, pre_transform=None):\n",
    "        super().__init__(root_dir, transform, pre_transform)\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.files = sorted(self.root_dir.glob(\"*.npz\"))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def get(self, idx):\n",
    "        file = self.files[idx]\n",
    "        data = np.load(file)\n",
    "\n",
    "        pos = torch.tensor(data[\"positions\"], dtype=torch.float64)         # shape (N, 3)\n",
    "        forces = torch.tensor(data[\"forces\"], dtype=torch.float64)         # shape (N, 3)\n",
    "        e_pot = torch.tensor(data[\"e_pot\"], dtype=torch.float64).view(1)   # scalar -> shape (1,)\n",
    "        z = torch.tensor(data[\"atom_types\"], dtype=torch.float64)             # shape (N,)\n",
    "\n",
    "        edge_index = self._fully_connected_edges(pos.shape[0])\n",
    "\n",
    "        # Optionally: create edge_attr as relative positions (optional but recommended)\n",
    "        edge_vec = pos[edge_index[0]] - pos[edge_index[1]]\n",
    "        edge_attr = edge_vec.norm(dim=1, keepdim=True)\n",
    "        edge_attr = torch.cat([edge_vec, edge_attr], dim=1)     # [n_edges, 4]\n",
    "\n",
    "\n",
    "        return Data(pos=pos, z=z.unsqueeze(1).double(), e_pot=e_pot, force=forces,\n",
    "                    edge_index=edge_index, edge_attr=edge_attr, edge_vec=edge_vec)\n",
    "\n",
    "    def _fully_connected_edges(self, num_atoms):\n",
    "        row, col = torch.meshgrid(\n",
    "            torch.arange(num_atoms), torch.arange(num_atoms), indexing=\"ij\"\n",
    "        )\n",
    "        edge_index = torch.stack([row.flatten(), col.flatten()], dim=0)\n",
    "        return edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a984b6",
   "metadata": {},
   "source": [
    "## Sanity Checks \n",
    "\n",
    "To check if your algorithm behaves in any meaningful way, or if we have to tune something in the algorithm or the training process, we need to plot the probability distribution of the data and later then the algorithm. So first, we are introducing data augmentation to make the algorithm invariant to translations and rotations of the molecule of interest. \n",
    "\n",
    "Here, it is absolutely important to rotate the forces if we rotate the molecule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "class RandomRotationTranslation:\n",
    "    def __init__(self, box_size):\n",
    "        \"\"\"\n",
    "        box_size: list or tensor of shape (3,) representing box lengths [Lx, Ly, Lz]\n",
    "        \"\"\"\n",
    "        self.box_size = torch.tensor(box_size, dtype=torch.float64)\n",
    "\n",
    "    def __call__(self, data: Data):\n",
    "        # Center molecule before rotation\n",
    "        pos = data.pos\n",
    "        center = pos.mean(dim=0, keepdim=True)\n",
    "        pos_centered = pos - center\n",
    "\n",
    "        # Apply random rotation\n",
    "        R = random_rotation_matrix()\n",
    "        pos_rotated = pos_centered @ R.T\n",
    "        force_rotated = data.force @ R.T\n",
    "\n",
    "        # Bounding box of rotated molecule\n",
    "        min_corner = pos_rotated.min(dim=0).values\n",
    "        max_corner = pos_rotated.max(dim=0).values\n",
    "        extent = max_corner - min_corner\n",
    "\n",
    "        # Compute safe margin for translation\n",
    "        margin = self.box_size - extent\n",
    "        if (margin < 0).any():\n",
    "            raise ValueError(f\"Molecule too large for bounding box: extent={extent}, box={self.box_size}\")\n",
    "\n",
    "        # Random translation that keeps molecule inside the box\n",
    "        translation = torch.rand(3, dtype=torch.float64) * margin - min_corner\n",
    "        pos_translated = pos_rotated + translation\n",
    "\n",
    "        # Update data\n",
    "        data.pos = pos_translated\n",
    "        data.force = force_rotated\n",
    "\n",
    "        # Update edge features\n",
    "        edge_vec = data.pos[data.edge_index[0]] - data.pos[data.edge_index[1]]\n",
    "        edge_attr = edge_vec.norm(dim=1, keepdim=True)\n",
    "        data.edge_vec = edge_vec\n",
    "        data.edge_attr = torch.cat([edge_vec, edge_attr], dim=1)\n",
    "\n",
    "        return data\n",
    "\n",
    "def random_rotation_matrix():\n",
    "    \"\"\"Uniform random rotation matrix using QR decomposition.\"\"\"\n",
    "    A = torch.randn(3, 3, dtype=torch.float64)\n",
    "    Q, R = torch.linalg.qr(A)\n",
    "    # Ensure right-handed coordinate system\n",
    "    if torch.det(Q) < 0:\n",
    "        Q[:, 2] *= -1\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c2799",
   "metadata": {},
   "source": [
    "### Plotting the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00590373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_force_distribution(dataset, file_name, batch_size=32, max_batches=10):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    forces = []\n",
    "\n",
    "    # Collect forces from a few batches\n",
    "    for i, data in enumerate(loader):\n",
    "        if not hasattr(data, 'force'):\n",
    "            raise AttributeError(\"Dataset items must have a `force` attribute.\")\n",
    "        x = data.z\n",
    "        f = data.force.view(-1, 3)  # shape: [num_nodes_total, 3]\n",
    "        f = f.view(-1, 3)\n",
    "        forces.append(f)\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "\n",
    "    forces = torch.cat(forces, dim=0).detach().numpy()  # [N, 3]\n",
    "\n",
    "    # Compute magnitudes and individual components\n",
    "    magnitudes = (forces ** 2).sum(axis=1) ** 0.5\n",
    "    fx, fy, fz = forces[:, 0], forces[:, 1], forces[:, 2]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.hist(fx, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force X\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.hist(fy, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force Y\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.hist(fz, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force Z\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.hist(magnitudes, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force Magnitude\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "data_path = \"methanol_aimd_data_prerun/\" #change to methanol_aimd_data_prerun if you use the prebuild dataset\n",
    "box_size= [10,10,10]\n",
    "transform = RandomRotationTranslation(box_size) #important to instantiate the translation\n",
    "dataset = NPZTrajectoryDataset(root_dir=data_path, transform=transform)\n",
    "dataset = NPZTrajectoryDataset(root_dir=data_path)\n",
    "plot_force_distribution(dataset=dataset, max_batches=200, file_name=\"force_distribution_dataset_data_aug.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7593a",
   "metadata": {},
   "source": [
    "## Algorithmic part \n",
    "\n",
    "Now comes the algorithmic part, where we explore some concepts of MLFFs. The algorithm of MLFFs needs to fulfil several requirements. \n",
    "\n",
    "* Needs to be rotation and translation invariant to the system as a whole (not just parts, that would be a different story)\n",
    "* Output negative and postive forces of any scale (no activation functions for the output layer) -> only activation functions in the hidden layers \n",
    "* Fit a conservative force field using differentiable activation functions SiLU \n",
    "* One could also derive the force from the negative gradient of the positions using automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a49bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "class ForceMPNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(1, hidden_dim)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(4, hidden_dim),  # vec_ij (3) + dist (1)\n",
    "            nn.SiLU()  ,\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.SiLU()  ,\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.update_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 3),  # Output force vector\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.z)                    # [n_nodes, hidden]\n",
    "        e = self.edge_mlp(data.edge_attr)             # [n_edges, hidden]\n",
    "        row, col = data.edge_index                    # edge from i = row to j = col\n",
    "        messages = self.message_mlp(x[col] * e)       # message from j to i\n",
    "        aggregated = scatter(messages, row, dim=0, dim_size=x.size(0), reduce='add')\n",
    "        force = self.update_mlp(aggregated)           # [n_nodes, 3]\n",
    "        return force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa32e87",
   "metadata": {},
   "source": [
    "## Trainig Loop \n",
    "\n",
    "The training loop is nothing special. Just fitting the forces with data augmentation and without gradient derivation of the force. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860493db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "num_steps = 5000\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Dataset class should already be defined as you provided earlier\n",
    "# Initialize the dataset\n",
    "data_path = \"methanol_aimd_data/\"\n",
    "box_size = [10,10,10]\n",
    "transform = RandomRotationTranslation(box_size) #important to instantiate the translation\n",
    "dataset = NPZTrajectoryDataset(root_dir=data_path, transform=transform)\n",
    "print(dataset[0].z.shape)\n",
    "print(dataset[0].z)\n",
    "print(len(dataset))\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model initialization\n",
    "model = ForceMPNN(hidden_dim=256)\n",
    "model = model.double()\n",
    "# Loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "loss_store = []\n",
    "for epoch in tqdm(range(1,num_steps+1), desc=\"Training MPNN on Methanol Trajectory\"):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = F.mse_loss(pred, batch.force)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    loss_store.append(total_loss/len(dataloader))\n",
    "    if epoch%100 == 0:\n",
    "        print(f\"Epoch {epoch:2d} | Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8082e",
   "metadata": {},
   "source": [
    "## Plot the loss and save the model for later\n",
    "\n",
    "You know that for sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "x = [i for i in range(len(loss_store))]\n",
    "plt.plot(x, loss_store)\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"MPNN_5k_epoch_64_batch_size_256_hidden_dim_labels_data_aug-SiLU.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15527758",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"mpnn_full_model_data_aug_SiLU_5000.pth\")\n",
    "model_path = \"mpnn_full_model_data_aug_SiLU_5000.pth\"\n",
    "model = torch.load(model_path, map_location=\"cpu\", weights_only=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0eab9",
   "metadata": {},
   "source": [
    "## Checking the probability distribution of the model \n",
    "\n",
    "We now check if the model is producing a reasonable probability distribution. Remember to change the data path if you are using different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_force_distribution_model(dataset, model, file_name, batch_size=32, max_batches=10):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    forces = []\n",
    "\n",
    "    # Collect forces from a few batches\n",
    "    for i, data in enumerate(loader):\n",
    "        if not hasattr(data, 'force'):\n",
    "            raise AttributeError(\"Dataset items must have a `force` attribute.\")\n",
    "        x = data.z\n",
    "        f = data.force.view(-1, 3)  # shape: [num_nodes_total, 3]\n",
    "        f = model(data)\n",
    "        f = f.view(-1, 3)\n",
    "        forces.append(f)\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "\n",
    "    forces = torch.cat(forces, dim=0).detach().numpy()  # [N, 3]\n",
    "\n",
    "    # Compute magnitudes and individual components\n",
    "    magnitudes = (forces ** 2).sum(axis=1) ** 0.5\n",
    "    fx, fy, fz = forces[:, 0], forces[:, 1], forces[:, 2]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.hist(fx, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force X\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.hist(fy, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force Y\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.hist(fz, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force Z\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.hist(magnitudes, bins=100, alpha=0.7, color='black')\n",
    "    plt.title(\"Force Magnitude\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "model_path = \"mpnn_full_model_data_aug_SiLU_5000.pth\"\n",
    "model = torch.load(model_path, map_location=\"cpu\", weights_only=False)\n",
    "data_path = \"methanol_aimd_data/\" #change for your data path \n",
    "dataset = NPZTrajectoryDataset(root_dir=data_path)\n",
    "plot_force_distribution_model(model=model, dataset=dataset, max_batches=200, file_name=\"force_distribution_mp_model_5000_data_aug_SiLU.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2f906",
   "metadata": {},
   "source": [
    "That's it for the training. Good job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfftutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
